ğŸ§  gpu-agent-opt

Unified AI Agent Framework for GPU Kernel Profiling, Scientific Computing, and CUDA Exploration

gpu-agent-opt is a Python package designed to orchestrate AI-style agentic workflows for Triton, CUDA, CuPy, cuDF, and advanced GPU programming patterns â€” combining automatic kernel discovery, profiling, and analysis with a knowledge-driven loop:

ğŸ‘‰ Sense â†’ Think â†’ Act â†’ Learn â†’ Reflect

The current focus is to build a one-stop GPU research & profiling layer that integrates deep learning graph compilers (PyTorch Inductor / XLA), scientific computing (CuPy / cuDF), and low-level CUDA primitives (e.g., coalesced memory, warp shuffle, tensor cores) into a single agentic profiling system.

âœ¨ Core Capabilities

ğŸ§  Agentic Kernel Profiler

Automatically discovers active GPU kernels during script execution using Nsight Systems.

Selects top kernels (based on occurrence or time) for detailed Nsight Compute profiling.

Generates structured summary reports (JSON) with SM and DRAM efficiency metrics.

ğŸ§ª Multi-Backend Context

Triton kernels (via PyTorch Inductor or custom)

Raw CUDA kernels (via NVRTC / PyCUDA / C++ extensions)

CuPy & cuDF for scientific array/dataframe computing

Planned: CUDA Graphs, Cooperative Groups, Tensor Cores, async copies, MIG partitioning.

ğŸ”¬ Profiler Integration

Nsight Systems for kernel discovery.

Nsight Compute for profiling top kernels with selected metrics (e.g., sm__throughput, dram__throughput).

Generates both per-kernel CSVs and aggregated summary.json.

ğŸ“š Knowledge Base / Reflection

reflect_history.json stores efficiency trends over multiple runs.

Helps identify consistently low-performing kernels and track improvements over time.

ğŸ›° Target Use Cases

Geospatial AI auto-annotation pipelines (DINOv2, SAM2, YOLO, NDWI/LBP preprocessing)

Deep learning inference/training profiling through PyTorch + Nsight

Scientific/HPC workloads (FFT, FDTD3D, conjugate gradient, Monte Carlo, etc.)

CUDA educational benchmarking (transpose, reduction, memory hierarchy, etc.)

Embedded GPU pipelines (Jetson Orin / RB5).

ğŸ“Š ğŸ§  Agentic Profiling Snapshot

The framework executes a five-stage loop to profile real GPU workloads:

Sense â†’ Discover kernels
Think â†’ Select top kernels
Act â†’ Run Nsight Compute on selected kernels
Learn â†’ Analyze & classify bottlenecks
Reflect â†’ Track efficiency trends over runs

## ğŸ“Š Example output from profiling a geospatial annotation pipeline

Below is a snapshot from a real profiling run on DINOv2 + SAM2 annotation pipeline:

![Profiling Snapshot](assets/profile_snapshot.png)
These metrics are stored in:

runs/profile_logs/.../summary.json â†’ per-run aggregated metrics

reflect_history.json â†’ longitudinal trend tracking (e.g., average SM & DRAM efficiency per run)

This forms the foundation for future agentic steps, such as:

Replacing inefficient PyTorch kernels with custom CUDA/Triton implementations

Adjusting launch configurations or fusing operators

Triggering code generation agents

ğŸ”¥ CUDA Samples Integration

The agent aims to provide a Pythonic exploration layer over classic CUDA patterns, using the official CUDA Samples as a baseline:

Memory & Data Movement: bandwidthTest, transpose, globalToShmemAsyncCopy, etc.

Computation Kernels: reduction, scan, GEMM tensor core examples.

Advanced Features: CUDA Graphs, Cooperative Groups, Async API.

Linear Algebra & Solvers: cuBLAS, cuSolver.

Signal & Image Processing: FFT (CUFFT), DCT, NPP.

Misc: deviceQuery, inlinePTX, cudaOpenMP, NVRTC runtime compilation.

All these are being wrapped progressively into Python interfaces and integrated with the profiler for analysis and future optimization.

ğŸ§ª Scientific + DL Interoperability

CuPy / cuDF kernels can be profiled alongside Triton / CUDA kernels in the same pipeline.

PyTorch Inductor graphs can be analyzed to identify candidate subgraphs for replacement.

Target: seamlessly combine high-level deep learning graphs with low-level profiling data.

ğŸ“¦ Installation

ğŸ‘‰ https://test.pypi.org/project/gpu-agent-opt/

pip install gpu-agent-opt


Development install:

git clone https://github.com/intelav/gpu_agent_opt.git
cd gpu_agent_opt
pip install -e .

ğŸ“Š Roadmap

âœ… Triton kernel detection through Inductor

âœ… Nsight Systems + Compute integration

âœ… Summary & Reflect history JSON generation

ğŸš§ CuPy / cuDF scientific profiling

ğŸš§ CUDA Samples wrapping

ğŸš§ Tensor Core profiling

ğŸš§ Multi-GPU / MIG profiling

ğŸš§ Autotuning (Triton / CUDA) â€” future

ğŸš§ Web dashboard for kernel search spaces & profiling results

ğŸ¤ Contributing

Contributions are very welcome, especially for:

Wrapping additional CUDA samples into Python bindings

Expanding scientific kernel coverage (FFT, solvers, etc.)

Profiling backends (CUPTI integration, Nsight scripting)

Building autotuning hooks (Triton, CUDA extensions)

ğŸ‘‰ Open issues & PRs on GitHub

ğŸ“œ License

MIT License â€” see LICENSE