# ðŸ§  **gpu-agent-opt**

**Unified AI Agent Framework for GPU Kernel Profiling, Scientific Computing, and CUDA Exploration**

`gpu-agent-opt` is a Python package designed to orchestrate **agentic workflows** for **Triton, CUDA, CuPy, cuDF**, and advanced GPU programming patterns â€” combining **kernel discovery**, **profiling**, and **analysis** with a knowledge-driven loop:

ðŸ‘‰ **Sense â†’ Think â†’ Act â†’ Learn â†’ Reflect**

The current focus is to build a **one-stop GPU research & profiling layer** that integrates:
- Deep learning graph compilers (PyTorch Inductor / XLA)  
- Scientific computing (CuPy / cuDF)  
- Low-level CUDA primitives (e.g., coalesced memory, warp shuffle, tensor cores)

---

## âœ¨ **Core Capabilities**

### ðŸ§  Agentic Kernel Profiler
- Discovers active GPU kernels during script execution using **Nsight Systems**.  
- Selects top kernels for detailed **Nsight Compute** profiling.  
- Generates structured summary reports (JSON) with SM and DRAM efficiency metrics.

### ðŸ§ª Multi-Backend Context
- âœ… **Triton kernels** (via PyTorch Inductor or custom)  
- âœ… **Raw CUDA kernels** (NVRTC / PyCUDA / C++ extensions)  
- âœ… **CuPy & cuDF** scientific kernels  
- ðŸš§ **Planned:** CUDA Graphs, Cooperative Groups, Tensor Cores, async copies, MIG.

### ðŸ”¬ Profiler Integration
- Nsight Systems â†’ Kernel discovery  
- Nsight Compute â†’ Per-kernel profiling (SM & DRAM metrics)  
- Exports both per-kernel CSV and aggregated `summary.json`.

### ðŸ“š Knowledge Base / Reflection
- `reflect_history.json` stores efficiency trends across runs.  
- Helps identify consistently low-performing kernels over time.

---

## ðŸ›° **Target Use Cases**
- Geospatial AI auto-annotation pipelines (DINOv2, SAM2, YOLO, NDWI/LBP preprocessing)  
- Deep learning inference/training profiling through PyTorch + Nsight  
- Scientific/HPC workloads (FFT, FDTD3D, conjugate gradient, Monte Carlo, etc.)  
- CUDA educational benchmarking (transpose, reduction, memory hierarchy, etc.)  
- Embedded GPU pipelines (Jetson Orin / RB5)

---

## ðŸ“Š **Agentic Profiling Snapshot**

The framework executes a **five-stage loop** to profile real GPU workloads:

| Stage   | Description                     |
|---------|----------------------------------|
| Sense   | Discover kernels                |
| Think   | Select top kernels              |
| Act     | Profile with Nsight Compute     |
| Learn   | Analyze & classify bottlenecks |
| Reflect | Track efficiency trends        |

### ðŸ“¸ Example output from profiling a geospatial annotation pipeline

Below is a snapshot from a real profiling run on DINOv2 + SAM2:

![Profiling Snapshot](assets/snapshot2.png)

The results are stored in:

- `runs/profile_logs/.../summary.json` â†’ per-run aggregated metrics  
- `reflect_history.json` â†’ longitudinal trend tracking

These form the basis for future **agentic actions**, such as:
- Replacing inefficient PyTorch kernels with custom CUDA/Triton implementations
- Adjusting launch configurations or fusing operators
- Triggering code-generation agents

---

## ðŸ”¥ **CUDA Samples Integration**

The agent provides a Pythonic layer over classic CUDA patterns (via official samples):

- **Memory & Data Movement**  
  `bandwidthTest`, `transpose`, `globalToShmemAsyncCopy`, `UnifiedMemoryStreams`

- **Computation Kernels**  
  `reduction`, `scan`, GEMM tensor core examples

- **Advanced Features**  
  CUDA Graphs, Cooperative Groups, Async API

- **Linear Algebra & Solvers**  
  cuBLAS, cuSolver

- **Signal & Image Processing**  
  CUFFT, DCT, NPP routines

- **Miscellaneous / Educational**  
  `deviceQuery`, `inlinePTX`, `cudaOpenMP`, NVRTC runtime compilation

---

## ðŸ§ª **Scientific + DL Interoperability**

- CuPy / cuDF kernels can be profiled alongside Triton / CUDA kernels.  
- PyTorch Inductor graphs can be analyzed to identify subgraphs for replacement.  
- Goal: Combine **high-level DL graphs** with **low-level profiling data**.

---

## ðŸ“¦ **Installation**

**TestPyPI**:  
ðŸ‘‰ [https://test.pypi.org/project/gpu-agent-opt/](https://test.pypi.org/project/gpu-agent-opt/)

```bash
pip install gpu-agent-opt
